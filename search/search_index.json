{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"PlexPipe - Multiplexed Image Analysis Pipeline","text":""},{"location":"#overview","title":"Overview","text":"<p>PlexPipe is an multiplex analysis pipeline that processes images through a series of modular steps, transforming raw whole-slide TIFF images into quantitative single-cell data.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Input Data: The pipeline accepts sets of individual TIFF files. It follows the naming conventions used by the Cell DIVE system. For specific requirements regarding file naming, refer to Input Data.</li> <li>Remote Data Sourcing: Seamlessly source and transfer large-scale imaging datasets from institutional endpoints or personal collections using Globus. This ensures secure and reliable data movement directly into your processing environment (see: Globus Integration).</li> <li>Data Integration: Outputs are stored as SpatialData objects, making them ready for downstream analysis within the scverse ecosystem or interactive exploration via the napari-spatialdata plugin.</li> <li>Flexible Execution: PlexPipe can be implemented in two ways based on your needs:<ul> <li>Local/Interactive: Utilize the provided Python scripts or Jupyter Notebooks for smaller datasets or pipeline prototyping (see Execution Modes).</li> <li>High-Throughput: For parallel processing and large-scale workflows, use the Nextflow-optimized version: plex-pipe-nextflow.</li> </ul> </li> </ul>"},{"location":"api/","title":"API Reference","text":"<p>This section contains the reference documentation for all modules in the pipeline.</p>"},{"location":"api/#plex_pipe.core_cutting.cutter.CoreCutter","title":"<code>CoreCutter(margin=0, mask_value=0)</code>","text":"<p>Extract rectangular or polygonal regions from images.</p> <p>Create a new cutter.</p> <p>Parameters:</p> Name Type Description Default <code>margin</code> <code>int</code> <p>Padding to apply around each core.</p> <code>0</code> <code>mask_value</code> <code>int</code> <p>Value used outside polygon masks.</p> <code>0</code>"},{"location":"api/#plex_pipe.core_cutting.cutter.CoreCutter.extract_core","title":"<code>extract_core(array, row)</code>","text":"<p>Extract a single core from the given image.</p> <p>Parameters:</p> Name Type Description Default <code>array</code> <code>ndarray | Array</code> <p>Source image.</p> required <code>row</code> <code>Series</code> <p>Metadata describing the core. Required fields include <code>row_start</code>, <code>row_stop</code>, <code>column_start</code>, <code>column_stop</code> and <code>poly_type</code>.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>numpy.ndarray: The extracted core image.</p>"},{"location":"analysis_steps/00_steps_overview/","title":"Analysis Steps","text":"<p>PlexPipe processes multiplexed whole-slide images through a sequence of modular steps, transforming raw imaging data into quantitative single-cell measurements.</p> <p>To run the pipeline, users must first create a configuration file that defines the parameters for all pipeline steps. This configuration file is the central control point for PlexPipe and is required throughout the entire workflow.</p> <p>While most steps run automatically based on the configuration, Step 1 (ROI Definition) and Step 3 (Quality Control) require user interaction via the Napari viewer. In these steps, users manually inspect the data, define regions of interest, and annotate imaging artefacts.</p>"},{"location":"analysis_steps/00_steps_overview/#1-roi-definition","title":"1. ROI Definition","text":"<p>Goal: Identify the boundaries of Region of Interest (ROI) within a whole-slide image.</p> <ul> <li>Input: A representative whole-slide image (usually DAPI).</li> <li>Output: A list of ROIs coordinates and their visual representation.</li> </ul>"},{"location":"analysis_steps/00_steps_overview/#2-roi-cutting","title":"2. ROI Cutting","text":"<p>Goal: Extract individual ROIs into separate SpatialData objects.</p> <ul> <li>Input: Raw OME-TIFF images and ROI coordinates.</li> <li>Output: Individual SpatialData (Zarr) objects for each ROI (images only).</li> </ul>"},{"location":"analysis_steps/00_steps_overview/#3-quality-control-qc","title":"3. Quality Control (QC)","text":"<p>Goal: Define image areas from which objects should be excluded (e.g. imaging artefacts, folded tissue, etc.).</p> <ul> <li>Input: SpatialData objects containing marker images.</li> <li>Output: User-defined exclusion shapes (added to SpatialData objects).</li> </ul>"},{"location":"analysis_steps/00_steps_overview/#4-image-processing","title":"4. Image Processing","text":"<p>Goal: Enhance images, segment objects and create derivative masks.</p> <ul> <li>Input: Core SpatialData objects.</li> <li>Output: SpatialData objects containing requested derivative images and masks.</li> </ul>"},{"location":"analysis_steps/00_steps_overview/#5-quantification","title":"5. Quantification","text":"<p>Goal: Generate single-cell quantitative data.</p> <ul> <li>Input: SpatialData objects containing Segmentation masks and intensity images.</li> <li>Output: AnnData tables containing single-cell feature matrices added to SpatialData objects.</li> </ul>"},{"location":"analysis_steps/01_roi_definition/","title":"ROI Definition","text":""},{"location":"analysis_steps/01_roi_definition/#overview","title":"Overview","text":"<p>The initial stage of the plex-pipe pipeline involves defining the coordinates for Regions of Interest (ROIs). These regions are subsequently extracted and processed as individual SpatialData objects.</p> <ul> <li>Input: A representative whole-slide image (usually DAPI).</li> <li> <p>Output:</p> <ul> <li>rois.pkl: Parameters defining ROIs.</li> <li>rois.csv: A human-readable definition of ROIs.</li> <li>rois.png: A visual overview of the defined ROIs.</li> </ul> </li> </ul> <p>This step is performed interactively using 01_roi_definition_demo Jupyter notebook.</p> <p>The notebook is divided into two parts:</p> <ul> <li>Manual Definition</li> <li>Automatic Detection</li> </ul> <p>Execute the notebook cells sequentially to progress through the ROI definition workflow.</p> <p>Utilizing SAM2 for automated image segmentation requires an auxiliary environment configuration and the specification of model checkpoints, see SAM2 Configuration and Environment Setup section.</p> <p>All ROIs (including SAM2 suggestions) are editable.</p>"},{"location":"analysis_steps/01_roi_definition/#drawing-rois-manually","title":"Drawing ROIs manually","text":"<p>The notebook requires the user to specify the path to the configuration file (<code>config_path</code>), which defines the target image and the specific resolution level to be utilized for ROI definition, see also config schema.</p> <p>When the resolution parameter remains unspecified, the loader defaults to the multi-resolution approach.</p> <p>Note</p> <p>Coordinate Scaling: All transformations between the Napari viewer and the final save files are handled automatically, ensuring coordinates are scaled back to the original full-resolution image shape.</p> <p>Manual definition of ROIs is performed using a Napari viewer with custom widgets.</p>"},{"location":"analysis_steps/01_roi_definition/#layers-in-the-viewer","title":"Layers in the viewer","text":"<ul> <li> <p>Signal Layer: The loaded image data.</p> </li> <li> <p>Frame Layer: A white rectangle framing the full image extent.</p> </li> <li> <p>ROIs Layer (Green): Use Napari's native shape tools to draw rectangles or polygons to define ROIs in this layer.</p> </li> <li> <p>Bounding Boxes Layer (Yellow): Automatically updated upon saving (Save ROIs Button) to reflect the extent of your ROIs.</p> </li> </ul>"},{"location":"analysis_steps/01_roi_definition/#interactive-controls","title":"Interactive Controls","text":"<p>You can find these buttons in the Napari dock widget on the left:</p> <ul> <li> <p>Display Saved ROIs: Reloads the ROIs from the path specified in your config.</p> </li> <li> <p>Save ROIs: Triggers saving of the output files (overwriting previous saves).</p> </li> <li> <p>Edge Width Slider: Dynamically adjusts the stroke thickness of shapes for better visibility on high-resolution images.</p> </li> </ul> <p></p>"},{"location":"analysis_steps/01_roi_definition/#automatic-roi-suggestions","title":"Automatic ROI suggestions","text":"<p>For slides with many regions (e.g., TMAs), the Segment Anything Model 2 (SAM2) can suggest ROIs.</p>"},{"location":"analysis_steps/01_roi_definition/#sam2-configuration-and-environment-setup","title":"SAM2 Configuration and Environment Setup","text":"<p>To utilize automated ROI suggestions, follow the installation protocols provided by the Segment Anything Model 2 (SAM2) and download the model checkpoints. Ensure that <code>plex-pipe</code> is installed within this dedicated SAM2 environment.</p> <p>SAM2 does not natively support Windows. For Windows-based workflows, you must install the Windows Subsystem for Linux (WSL) and configure the SAM2 environment within the WSL distribution.</p> <p>Cross-Platform Execution:</p> <ul> <li>Windows: The code automatically detects the OS and routes the SAM2 command through WSL.</li> <li>Linux: Runs directly using the specified sam_env.</li> </ul>"},{"location":"analysis_steps/01_roi_definition/#defining-model-and-environment-paths","title":"Defining Model and Environment Paths","text":"<p>The notebook requires the absolute paths to both the SAM2 model checkpoints and the Python executable of the SAM2 environment.</p> <p>You may define these parameters manually as a dictionary:</p> <pre><code>sam_config = {\n    'model_path': '/mnt/d/sam2_test/sam2', # Absolute path to SAM2 checkpoints\n    'sam_env': '/home/kasia/miniforge3/envs/sam2-env/bin/python' # Path to SAM2 Python executable\n}\n</code></pre> <p>Alternatively, use the <code>load_workstation_config</code> helper function to import settings from a YAML file. This approach allows a single centralized file to manage configurations for multiple workstations based on their hostnames.</p> <p>The file structure is as follows:</p> <pre><code>workstations:\n  WORKSTATION_HOSTNAME: # As returned by platform.node()\n    model_path: \"path/to/model\"\n    sam2_env: \"path/to/environment/python\"\n</code></pre> <p>Template configuration files are available in the project's examples folder.</p> <p>Note</p> <p>When configuring the workstation YAML, provide WSL-compliant paths (e.g., <code>/mnt/d/...</code>). However, the main analysis configuration file does not require modification; the notebook automatically handles path translations between Windows and WSL during execution.</p>"},{"location":"analysis_steps/01_roi_definition/#filtering-parameters","title":"Filtering Parameters","text":"<p>Adjust the following variables within the notebook to refine the model's output:</p> <ul> <li><code>nominal_small_size</code>: The expected diameter (in pixels) of the target objects. Use the Napari viewer to measure and determine this value for your specific dataset.</li> <li><code>min_delta_factor</code> / <code>max_delta_factor</code>: Multipliers used to establish the area thresholds for filtering masks that are either too small or too large relative to the nominal size.</li> </ul>"},{"location":"analysis_steps/01_roi_definition/#workflow","title":"Workflow","text":"<p>The underlying code for these steps is available in the notebook cells, allowing for full customization; however, the standard workflow is outlined below:</p> <ul> <li>Configure Parameters: Define the filtering criteria as described above.</li> <li>Execute Segmentation: Run the SAM2-specific cells to initiate the automated detection. The ROIs and bounding boxes will be automatically populated into the Napari viewer for review and manual correction.</li> <li>Finalize and Save: Once the regions are validated, manually trigger the saving protocol via the <code>Save ROIs</code> button.</li> <li>Contrast Sensitivity: The SAM2 subprocess utilizes the current Contrast Limits of the Napari 'signal' layer to normalize the image prior to segmentation. Ensure the image contrast is stretched to clearly distinguish objects of interest; this adjustment can also be utilized to exclude dim background artifacts.</li> <li>Dynamic Resolution (Multi-Resolution Inputs): If the input image is multi-resolution (<code>im_level</code> is not specified), SAM2 performs segmentation on the resolution level currently active in the viewer.<ul> <li>Object size parameters are adjusted automatically to match the current scale.</li> <li>If the workstation encounters memory errors, zoom out to a lower resolution level for segmentation.</li> <li>If the ROI geometries are insufficiently precise, zoom in to a higher resolution level to improve segmentation accuracy.</li> </ul> </li> </ul>"},{"location":"analysis_steps/01_roi_definition/#roi-output-schema","title":"ROI Output Schema","text":"<p>The primary output is <code>rois.pkl</code>, which defines the geometry of each roi. This schema is provided for informational purposes only; the pipeline manages this data structure automatically, and no manual modification is required by the user.</p> Column Description <code>roi_name</code> Unique identifier for the roi (e.g., <code>ROI_000</code>, <code>ROI_0011</code>). <code>row_start</code> Y-coordinate of the top edge of the bounding box. <code>row_stop</code> Y-coordinate of the bottom edge of the bounding box. <code>column_start</code> X-coordinate of the left edge of the bounding box. <code>column_stop</code> X-coordinate of the right edge of the bounding box. <code>poly_type</code> Type of shape (<code>rectangle</code> or <code>polygon</code>). <code>polygon_vertices</code> (y, x) coordinates defining the polygon. <p>Example output files can be found in the examples folder.</p>"},{"location":"analysis_steps/02_roi_cutting/","title":"ROI Cutting","text":""},{"location":"analysis_steps/02_roi_cutting/#overview","title":"Overview","text":"<p>Once ROIs are defined, the pipeline extracts these regions from the original TIF(F) files. This step handles channel selection logic, allowing you to exclude specific channels, or select the best version of a repeated marker.</p> <ul> <li>Input: TIF(F) images and ROI coordinates (<code>rois.pkl</code>).</li> <li>Output: Individual SpatialData (Zarr) objects for each ROI (images only).</li> </ul> <p>Parameters of this step are defined in the ROI Cutting part of the config file.</p>"},{"location":"analysis_steps/02_roi_cutting/#data-sourcing","title":"Data Sourcing","text":"<p>This module supports dual modes of operation for data retrieval: Local and Globus. For comprehensive instructions on configuring Globus for remote data sourcing, see Globus Settings documentation and the corresponding demonstration notebook.</p>"},{"location":"analysis_steps/02_roi_cutting/#execution","title":"Execution","text":"<p>This module is fully parameterized via the configuration file and does not require manual intervention. Consequently, it can be executed via a Jupyter Notebook, standalone script, or as a component of the Nextflow pipeline; further details are available in the Execution Modes documentation.</p>"},{"location":"analysis_steps/02_roi_cutting/#notebook-workflow","title":"Notebook workflow","text":"<p>The example Jupyter Notebook demonstrates the execution workflow using locally available data.</p> <p>To complete the process, execute the following sections sequentially:</p> <ul> <li>Read in config: Specify the pathway to the analysis configuration file and load the required settings.</li> <li>Define the logger: Initialize the logging protocol to track execution progress and document the process.</li> <li>Define ROIs for processing: Ingests the ROI parameters into a Pandas DataFrame. A demonstration cell is provided to truncate this DataFrame for rapid testing purposes.</li> <li>Discover signal channels: Identifies available TIFF images and implements the channel selection logic. A demonstration cell is included to show how to subset the channel list for testing.</li> <li>Run ROI cutting: Triggers the ROI extraction process utilizing the local file sourcing strategy.</li> </ul>"},{"location":"analysis_steps/02_roi_cutting/#script-execution","title":"Script execution","text":"<pre><code>python 02_cut_rois.py --exp_config ../examples/example_pipeline_config.yaml\n</code></pre>"},{"location":"analysis_steps/03_quality_control/","title":"Quality Control (QC)","text":""},{"location":"analysis_steps/03_quality_control/#overview","title":"Overview","text":"<p>This is a manual step performed by user drawing exclusion shapes. To support it we provide a napari widget that can be easily operated from a Jupyter notebook.</p> <ul> <li>Input: SpatialData objects containing marker images.</li> <li>Output: User-defined exclusion shapes for each marker (added to SpatialData objects).</li> </ul> <p>Specified polygons will be used in the quantification step to create masks in the AnnData tables marking if an intensity-based properties for a given channel/marker should be included in the downstream analysis.</p> <p>Parameters of this step are defined in the Quality Control (QC) part of configuration.</p>"},{"location":"analysis_steps/03_quality_control/#notebook-workflow","title":"Notebook Workflow","text":"<p>Execute the following sections within the Quality Control notebook sequentially:</p> <ul> <li>Read in config: Specify the absolute pathway to the analysis configuration file to initialize the session settings.</li> <li>Select SpatialData Object: This section generates a list of available SpatialData objects. Adjust the <code>ind</code> parameter to select the specific ROI for review.</li> <li>Initialize Napari QC Widget: Launches an interactive Napari viewer equipped with a custom widget designed for rapid data annotation:<ul> <li>Marker Navigation: Facilitates efficient browsing of markers within the SpatialData object via forward/backward navigation arrows or by selecting a specific marker from the dropdown menu.</li> <li>Interactive Annotation: A dedicated shapes layer is automatically generated for each marker. Use Napari's native shape tools to delineate regions for exclusion.</li> <li>Automated Persistence: If a marker already contains existing exclusion geometries, they are automatically loaded into the viewer for further editing.</li> <li>Data Export: Utilize the <code>Save</code> and <code>Save All</code> buttons to commit exclusion polygons for the active marker or the entire ROI, respectively.</li> <li>Session Termination: Close the Napari viewer interface once the annotations are completed and saved.</li> </ul> </li> <li>Iterative Review: Return to the Select SpatialData Object section, update the object index, and repeat the annotation process for all remaining ROIs.</li> </ul> <p></p>"},{"location":"analysis_steps/03_quality_control/#alternative-execution-workflows","title":"Alternative Execution Workflows","text":"<p>Since Step 2 (ROI Extraction), Step 4 (Image Processing), and Step 5 (Quantification) are fully automated and require no manual intervention, they may be executed sequentially. In this configuration, the Quality Control (QC) stage can be deferred until after the quantification is complete. This is possible because the QC process appends exclusion masks directly to the <code>AnnData</code> tables, and these geometries are not a prerequisite for the quantification itself.</p> <p>To implement quality control after the quantification phase, please refer to the post-quantification QC notebook.</p>"},{"location":"analysis_steps/04_image_processing/","title":"Image Processing","text":""},{"location":"analysis_steps/04_image_processing/#overview","title":"Overview","text":"<p>The Image Processing step is a highly flexible stage of the PlexPipe workflow, defined by an ordered list of processors specified in the configuration file. Each processor operates on image or mask data and can generate new derivative elements.</p> <ul> <li>Input: Core <code>SpatialData</code> objects.</li> <li>Output: <code>SpatialData</code> objects augmented with derived images and/or masks.</li> </ul> <p>This step supports the following categories of operations:</p> <ul> <li> <p>Image Filtering   Intensity-based transformations such as normalization, denoising, smoothing, and computation of summary images (e.g. mean or maximum projections).</p> </li> <li> <p>Object Segmentation   Identification of nuclei and cells using deep-learning\u2013based segmentation models.   Currently supported models include Cellpose and InstanSeg.</p> </li> <li> <p>Mask Building   Construction of derived masks, such as cytoplasmic rings using boolean operations.</p> </li> </ul> <p>All parameters controlling this step are defined in the Image Processing section of the configuration reference.</p>"},{"location":"analysis_steps/04_image_processing/#persistence","title":"Persistence","text":"<p>Newly generated images and masks can either be stored permanently within the <code>SpatialData</code> object or created only as temporary intermediates.</p> <p>Temporary outputs are useful for multi-step workflows\u2014for example, normalized intensity images may be generated solely to serve as input for a segmentation processor without being persisted in the final dataset.</p>"},{"location":"analysis_steps/04_image_processing/#execution","title":"Execution","text":"<p>This module is fully parameterized via the configuration file and does not require manual intervention. Consequently, it can be executed via a Jupyter Notebook, standalone script, or as a component of the Nextflow pipeline; further details are available in the Execution Modes documentation.</p>"},{"location":"analysis_steps/04_image_processing/#notebook-workflow","title":"Notebook workflow","text":"<p>The example Jupyter Notebook demonstrates the execution workflow using locally available data.</p> <p>To complete the process, execute the following sections sequentially:</p> <ul> <li>Read in config: Specify the path to the analysis configuration file and load the required settings.</li> <li>Specify the overwriting strategy: Set the <code>OVERWRITE_FLAG</code>. If <code>False</code>, the pipeline will throw an error to prevent overwriting existing resources. If <code>True</code>, existing resources will be replaced. Use with caution!</li> <li>Define the logger: Initialize the logging protocol to track execution progress and document the processing steps.</li> <li>Define ROIs for processing: Identify the <code>SpatialData</code> objects to be processed. A demonstration cell is provided to truncate this list for faster testing.</li> <li>Setup processors: Initialize the processing objects defined in your configuration. These objects are created once and reused across all ROIs.</li> <li>Run ROI Processing: Execute the list of processing steps for each ROI. Note that the pipeline automatically validates each <code>SpatialData</code> object immediately before it is processed. An optional validation cell is also provided to run this check for all objects in the list upfront, ensuring every ROI has the required components before starting the full execution.</li> </ul>"},{"location":"analysis_steps/04_image_processing/#script-execution","title":"Script execution","text":"<pre><code>python 04_segment.py --exp_config ../examples/example_pipeline_config.yaml --overwrite\n</code></pre>"},{"location":"analysis_steps/05_quantification/","title":"Quantification","text":""},{"location":"analysis_steps/05_quantification/#overview","title":"Overview","text":"<p>The final step extracts features from the segmented objects and stores them in the <code>AnnData</code> table(s) within <code>SpatialData</code> objects.</p> <ul> <li>Input: <code>SpatialData</code> objects containing segmentation masks and intensity images.</li> <li>Output: <code>AnnData</code> tables containing single-cell feature matrices added to <code>SpatialData</code> objects.</li> </ul> <p>Parameters of this step are defined in the Quantification part of configuration.</p>"},{"location":"analysis_steps/05_quantification/#supported-features","title":"Supported features","text":"<ul> <li>Morphological Features: Geometric attributes such as area, centroid, eccentricity, and orientation. All skimage.measure.regionprops properties are supported.</li> <li>Intensity Features: Statistical summaries (e.g., mean or median expression) for specified markers across the masked regions.</li> </ul> Feature Name Source / Implementation Description mean Skimage: <code>mean_intensity</code> Standard intensity property from <code>skimage.measure.regionprops</code>. max Skimage: <code>max_intensity</code> Standard intensity property from <code>skimage.measure.regionprops</code>. min Skimage: <code>min_intensity</code> Standard intensity property from <code>skimage.measure.regionprops</code>. median Custom: <code>calculate_median</code> Calculates the median intensity of the region. sum Custom: <code>calculate_sum</code> Calculates the sum intensity of the region. std Custom: <code>calculate_std</code> Calculates the standard deviation of intensity of the region."},{"location":"analysis_steps/05_quantification/#linking-anndata-tables-to-segmentation-masks","title":"Linking AnnData Tables to Segmentation Masks","text":"<p>In the <code>SpatialData</code> framework, every table should ideally be linked to a set of regions (masks). You can choose between two primary organizational strategies:</p>"},{"location":"analysis_steps/05_quantification/#option-1-distributed-tables-matching-links","title":"Option 1: Distributed Tables (Matching Links)","text":"<p>Separate quantification groups are defined to create distinct AnnData tables for each mask. * Example: A \"cell\" table linked to the cell mask and a \"nucleus\" table linked to the nucleus mask. * Benefit: Provides a strict 1:1 mapping between the table rows and the spatial labels.</p>"},{"location":"analysis_steps/05_quantification/#option-2-consolidated-table-single-link","title":"Option 2: Consolidated Table (Single Link)","text":"<p>Results from multiple masks are stored in a single AnnData table. * Example: Measurements for both \"cell\" and \"nucleus\" regions are stored in one table and linked to the \"cell\" segmentation mask. * Benefit: Simplifies downstream analysis by keeping all properties of a biological cell in one place.</p> <p>Both approaches are supported; choose the one that best fits your downstream analysis workflow.</p>"},{"location":"analysis_steps/05_quantification/#execution","title":"Execution","text":"<p>This module is fully parameterized via the configuration file and does not require manual intervention. Consequently, it can be executed via a Jupyter Notebook, standalone script, or as a component of the Nextflow pipeline; further details are available in the Execution Modes documentation.</p>"},{"location":"analysis_steps/05_quantification/#notebook-workflow","title":"Notebook workflow","text":"<p>The example Jupyter Notebook demonstrates the execution workflow using locally available data.</p> <p>To complete the process, execute the following sections sequentially:</p> <ul> <li>Read in config: Specify the path to the analysis configuration file and load the required settings.</li> <li>Specify the overwriting strategy: Set the <code>OVERWRITE_FLAG</code>. If <code>False</code>, the pipeline will throw an error to prevent overwriting existing table. If <code>True</code>, existing table will be replaced. Use with caution!</li> <li>Define the logger: Initialize the logging protocol to track execution progress and document the processing steps.</li> <li>Define ROIs for processing: Identify the <code>SpatialData</code> objects to be processed. A demonstration cell is provided to truncate this list for faster testing.</li> <li>Setup quantifiers: Initialize the quantifying objects defined in your configuration. These objects are created once and reused across all ROIs.</li> <li>Run ROIs Quantification: Quantify the ROIs.</li> </ul>"},{"location":"analysis_steps/05_quantification/#script-execution","title":"Script execution","text":"<pre><code>python 05_quantify.py --exp_config ../examples/example_pipeline_config.yaml --overwrite\n</code></pre>"},{"location":"configuration/channel-selection/","title":"\ud83c\udfaf Channel Selection Logic","text":""},{"location":"configuration/channel-selection/#terminology","title":"Terminology","text":"<p>To understand how channels are selected, it is important to distinguish between:</p> <ul> <li>Marker Name: The biological target being imaged (e.g., <code>DAPI</code>, <code>CD44</code>, <code>pRB</code>). This is derived from the filename.</li> <li>Channel Name: The unique identifier for a specific image acquisition, combining the round number and the marker name (e.g., <code>001_DAPI</code>, <code>002_CD44</code>). This format (<code>{round:03d}_{marker}</code>) allows the pipeline to distinguish between the same marker imaged in different rounds.</li> </ul> <p>The pipeline supports fine-grained control over which imaging channels are included in processing. This is essential because:</p> <ul> <li>The same marker may be imaged multiple times across rounds (e.g., re-staining or optimization).</li> <li>DAPI is typically acquired in every round for registration but usually only one version should be kept for the analysis.</li> </ul> <p>The selection process follows this logic:</p>"},{"location":"configuration/channel-selection/#1-default-behavior-if-no-overrides","title":"1. Default Behavior (if no overrides)","text":"<ul> <li>For each marker imaged in multiple rounds, the latest round is used by default.</li> <li>For DAPI, only <code>001_DAPI</code> is included unless specified otherwise.</li> </ul>"},{"location":"configuration/channel-selection/#2-using-include_channels","title":"2. Using <code>include_channels</code>","text":"<ul> <li>This is a list of channel names like <code>002_CD44</code>, <code>001_DAPI</code>.</li> <li>If set, only these channels are included for a given marker \u2014 they override automatic selection.</li> <li>Use this to force inclusion of earlier rounds or include duplicates for comparison.</li> </ul>"},{"location":"configuration/channel-selection/#3-using-exclude_channels","title":"3. Using <code>exclude_channels</code>","text":"<ul> <li>This is a list of channel names to skip.</li> <li>If <code>include_channels</code> is not set, <code>exclude_channels</code> can be used to remove undesired versions.</li> <li>Example: to exclude <code>003_pRB</code> in favor of earlier versions (or none).</li> </ul>"},{"location":"configuration/channel-selection/#4-using-use_markers","title":"4. Using <code>use_markers</code>","text":"<ul> <li>This is a list of base marker names (like <code>DAPI</code>, <code>pRB</code>, <code>CD44</code>) after stripping the round prefix.</li> <li>After all other filtering, <code>use_markers</code> is applied as a final filter.</li> <li>Use it to narrow the final channel set to specific markers, regardless of which round was selected.</li> </ul>"},{"location":"configuration/channel-selection/#5-using-ignore_markers","title":"5. Using <code>ignore_markers</code>","text":"<ul> <li>This is a list of base marker names to exclude from the final set.</li> <li>It is applied after <code>use_markers</code>.</li> <li>Use it to discard specific markers entirely (e.g. if a marker failed quality control across all rounds).</li> </ul>"},{"location":"configuration/channel-selection/#examples","title":"Examples","text":""},{"location":"configuration/channel-selection/#example-1-default-automatic-selection","title":"Example 1: Default automatic selection","text":"<pre><code>include_channels: []\nexclude_channels: []\nuse_markers: []\n</code></pre> <ul> <li>Keeps only the latest round per marker, and <code>001_DAPI</code>.</li> </ul>"},{"location":"configuration/channel-selection/#example-2-force-earlier-prb-round-to-be-used","title":"Example 2: Force earlier pRB round to be used","text":"<pre><code>include_channels: [\"001_pRB\"]\nuse_markers: []\n</code></pre> <ul> <li><code>001_pRB</code> is used even if <code>003_pRB</code> exists.</li> </ul>"},{"location":"configuration/channel-selection/#example-3-exclude-a-problematic-round","title":"Example 3: Exclude a problematic round","text":"<pre><code>exclude_channels: [\"003_CD44\"]\n</code></pre> <ul> <li>Automatically selects an earlier round (if available) for CD44.</li> </ul>"},{"location":"configuration/channel-selection/#example-4-only-process-dapi-and-cd44","title":"Example 4: Only process DAPI and CD44","text":"<pre><code>use_markers: [\"DAPI\", \"CD44\"]\n</code></pre> <ul> <li>Filters final output to only include these two base markers.</li> </ul>"},{"location":"configuration/channel-selection/#conflicts-and-priority","title":"Conflicts and Priority","text":"<ul> <li>If a channel is listed in both <code>include_channels</code> and <code>exclude_channels</code>, a <code>ValueError</code> is raised.</li> <li><code>use_channels</code> is applied last, on the base names after channel selection.</li> </ul>"},{"location":"configuration/config_overview/","title":"\ud83d\udd27 Configuration","text":"<p>The configuration file serves as the central blueprint for the PlexPipe analysis. It provides parameters for all stages of the pipeline divided into sections corresponding to the analysis steps.</p> <p>This configuration is defined in a YAML file; you can find a deep dive into the syntax at YAML official website, but the description and examples below should be more than enough to get you started.</p>"},{"location":"configuration/config_overview/#reproducibility-and-provenance","title":"Reproducibility and Provenance","text":"<p>To maintain a reliable audit trail, avoid modifying parameters once a step has been completed. The configuration file, paired with the resulting log files, serves as the formal documentation for the pipeline execution.</p>"},{"location":"configuration/config_overview/#config-validation","title":"Config Validation","text":"<p>To ensure your configuration is valid, the system validates your input against a predefined schema.</p> <p>Validation Rules:</p> <ul> <li> <p>Required Fields: These must be present in your configuration file. If a required field is missing, the application will return an error.</p> </li> <li> <p>Optional Fields: These are labeled as (optional). You can choose to:</p> <ul> <li>Omit them entirely (the system will use its default behavior).</li> <li>Set them to null (or ~) to explicitly signify no custom value.</li> <li>Provide a custom value to override the default.</li> </ul> </li> </ul>"},{"location":"configuration/config_overview/#path-format","title":"Path Format","text":"<p>When entering file paths in this configuration file, always use the forward slash (/) as the folder separator, even on Windows. The backslash (\\) is a \"special character\" in YAML. Using it can cause errors or require you to \"double-up\" your slashes (e.g., C:\\\\Users).</p> <p>Correct: C:/path/to/images Avoid: C:\\path\\to\\images.</p>"},{"location":"configuration/config_overview/#examples","title":"Examples","text":"<p>Full example configuration files can be found in the examples folder.</p>"},{"location":"configuration/reference/","title":"Reference","text":"<p>The following sections detail the configuration parameters for each step of the pipeline.</p>"},{"location":"configuration/reference/#general-settings","title":"General Settings","text":"<p>This section defines the fundamental paths and naming conventions for the analysis run, including the source image directory and the output location.</p> <pre><code>general:\n  image_dir: C:/path/to/images\n  analysis_name: experiment_01\n  analysis_root_dir: C:/analysis_out\n  log_dir: null\n</code></pre> Key Type Description <code>image_dir</code> <code>Path</code> Source directory with tiff images. For differences between the local and Globus use see Input Data. <code>analysis_name</code> <code>str</code> Name of the analysis run. <code>analysis_root_dir</code> <code>Path</code> Analysis output base directory. Analysis will be saved in <code>analysis_toot_dir/analysis_name</code> referred to as <code>analysis_dir</code>. <code>log_dir</code> <code>Path</code> (optional) Custom log directory. Defaults to <code>analysis_dir/logs</code>."},{"location":"configuration/reference/#roi-definition","title":"ROI Definition","text":"<p>This section configures the automatic detection of tissue cores. It specifies the image used for detection and the parameters for the Segment Anything Model (SAM2) to accurately identify core boundaries.</p> <pre><code>core_detection:\n  detection_image: \"BLCA-1_1.0.4_R000_DAPI__FINAL_F.ome.tif\"\n  core_info_file_path: null\n  im_level: 6\n</code></pre> Key Type Description <code>detection_image</code> <code>str</code> Required. Name of the image in <code>image_dir</code> used for defining cores. <code>roi_info_file_path</code> <code>Path</code> (optional) Custom path for core coordinates. Defaults to <code>analysis_dir/rois.pkl</code>. <code>im_level</code> <code>float</code> (optional) Pyramid level to read from the image for core definition. If not specified, all pyramid levels are read from the input image."},{"location":"configuration/reference/#roi-cutting","title":"ROI Cutting","text":"<p>This section controls the extraction of individual ROIs from the original whole-slide images. It allows for precise channel selection, definition of output directories, and configuration of core processing parameters such as margins and masking.</p> <pre><code>core_cutting:\n  cores_dir_tif: null\n  cores_dir_output: null\n\n  include_channels:\n  exclude_channels:\n    - 008_ECad\n  use_markers:\n  ignore_markers:\n    - Antibody1\n  margin: 0\n  mask_value: 0\n  transfer_cleanup_enabled: True\n  core_cleanup_enabled: True\n</code></pre> Key Type Description <code>cores_dir_tif</code> <code>Path</code> (optional) Temporary folder to store extracted TIFFs for each core. Defaults to <code>analysis_dir/temp</code>. <code>cores_dir_output</code> <code>Path</code> (optional) Final destination for SpatialData (Zarr) outputs. Defaults to <code>analysis_dir/cores</code>. <code>include_channels</code> <code>list[str]</code> (optional) List of channel names to include. <code>exclude_channels</code> <code>list[str]</code> (optional) List of channel names to exclude. <code>use_markers</code> <code>list[str]</code> (optional) List to restrict markers to analyze. <code>ignore_markers</code> <code>list[str]</code> (optional) List to ignore markers. <code>margin</code> <code>int</code> (optional) Number of pixels to pad around each bounding box when cutting cores. Defaults to 0. <code>mask_value</code> <code>int</code> (optional) Value used to fill background for polygonal core masks. Defaults to 0. <code>transfer_cleanup_enabled</code> <code>bool</code> (optional) Whether to delete temporary files downloaded via Globus after the run. Defaults to False. <code>core_cleanup_enabled</code> <code>bool</code> (optional) Whether to delete TIFFs from the temporary storage in <code>cores_dir_tif</code> after core assembly. Defaults to False. For details see Input Data. <p>Parameters <code>include_channels</code>, <code>exclude_channels</code>, <code>use_markers</code> and <code>ignore_markers</code> provide a fine-grained control over which imaging channels are included in processing. See Channel Selection Logic for details.</p>"},{"location":"configuration/reference/#quality-control","title":"Quality Control","text":"<p>This section manages quality control parameters, specifically defining prefixes for exclusion masks. These masks are used to filter out artifacts or unwanted regions from downstream analysis.</p> <pre><code>qc:\n  prefix: qc_exclude\n</code></pre> Key Type Description <code>prefix</code> <code>str</code> (optional) Prefix for shapes used for quality control exclusion. Shapes named <code>{prefix}_{marker}</code> will be used to mask out objects for specific markers."},{"location":"configuration/reference/#image-processing","title":"Image Processing","text":"<pre><code>additional_elements:\n\n  - category: image_enhancer\n    type: normalize\n    input: [DAPI, HLA1]\n    output: \"${input}_norm\"\n    parameters:\n      low: 1\n      high: 99.8\n    keep: false\n\n  - category: object_segmenter\n    type: instanseg\n    parameters:\n      model: fluorescence_nuclei_and_cells\n      pixel_size: 0.3\n      resolve_cell_and_nucleus: true\n      cleanup_fragments: true\n      clean_cache: true\n      normalise: false\n    input:\n      - DAPI_norm\n      - HLA1_norm\n    output:\n      - instanseg_nucleus\n      - instanseg_cell\n    keep: true\n\n  - category: mask_builder\n    type: ring\n    input:\n        - instanseg_nucleus\n    output: ring\n    parameters:\n      outer: 8\n      inner: 2\n    keep: true\n</code></pre> <p>The pipeline allows for flexible image processing steps defined in the Processors list. Each entry in this list is a processing unit that takes inputs (images or labels), performs an operation, and produces outputs. Processing steps are executed sequentially, meaning the order of the list determines the flow of data, and the output of one step is typically required for the next.</p>"},{"location":"configuration/reference/#structure-of-an-element","title":"Structure of an Element","text":"Key Type Description <code>category</code> <code>str</code> The category of the operation. Options: <code>image_enhancer</code>, <code>object_segmenter</code>, <code>mask_builder</code>. <code>type</code> <code>str</code> The specific operation name (e.g., <code>normalize</code>, <code>instanseg</code>). <code>input</code> <code>str</code> | <code>list</code> The name(s) of input images or channels. <code>output</code> <code>str</code> | <code>list</code> The name(s) assigned to the results. Supports variable expansion like <code>${input}_norm</code>. <code>parameters</code> <code>dict</code> (optional) Specific parameters for the operation. <code>keep</code> <code>bool</code> (optional) Whether to save the output to the final Zarr file (<code>true</code>) or keep it temporary (<code>false</code>). Defaults to <code>false</code>. <p>For a complete list of available operations and their parameters, see Processors.</p>"},{"location":"configuration/reference/#quantification","title":"Quantification","text":"<p>The <code>quant</code> section allows you to define one or more quantification tasks. Each entry in the list corresponds to a separate AnnData table that will be generated and stored in the SpatialData object. This is useful if you have multiple segmentation results (e.g., cells and nuclei, or different cell segmentation models) and want to quantify them independently. Example below specifies only a single AnnData table to be created ('instanseg_table').</p> <pre><code>quant:\n  - name: instanseg_table\n    masks:\n      nucleus: instanseg_nucleus\n      cell: instanseg_cell\n      ring: ring\n      cyto: cytoplasm\n    layer_connection: instanseg_cell\n    morphological_properties:\n      - label\n      - centroid\n      - area\n    intensity_properties:\n      - median\n    markers_to_quantify:\n      - DAPI\n      - HLA1\n    add_qc_masks: True\n</code></pre> Key Type Description <code>name</code> <code>str</code> Name of the output AnnData table to be saved in the SpatialData object. <code>masks</code> <code>dict[str, str]</code> Dictionary mapping suffixes (e.g., nucleus, cell) to the actual mask layer names in the SpatialData object. <code>layer_connection</code> <code>str</code> (optional) The mask layer name to which the table should be linked (e.g. for visualization in Napari Spatialdata plugin). <code>morphological_properties</code> <code>list[str]</code> (optional) List of morphological features to calculate. 'Label' is added automatically if absent from the custom list to identify objects. Defaults to [\"label\", \"centroid\", \"area\", \"eccentricity\", \"solidity\", \"perimeter\", \"euler_number\"]. <code>intensity_properties</code> <code>list[str]</code> (optional) List of intensity metrics to calculate. Defaults to ['mean', 'median']. <code>markers_to_quantify</code> <code>list[str]</code> (optional) List of specific markers to quantify itensity properties. If omitted, all available channels are quantified. <code>add_qc_masks</code> <code>bool</code> (optional) If True, uses polygons defined in the QC step to create a mask layer in the AnnData table indicating which objects are from the accepted regions. Defaults to False. <p>For <code>morphological_properties</code>, any property supported by skimage.measure.regionprops can be used.</p> <p>For <code>intensity_properties</code>, currently implemented metrics include <code>mean</code>, <code>median</code> <code>min</code>, <code>max</code>, <code>std</code> and <code>sum</code>. If you require other metrics, please open an issue on GitHub.</p>"},{"location":"configuration/reference/#storage-settings","title":"Storage Settings","text":"<p>This section defines the storage parameters for the resulting SpatialData objects (Zarr files). It controls performance-related settings such as chunk sizes and the generation of multi-scale image pyramids.</p> <pre><code>sdata_storage:\n  chunk_size: [1, 512, 512]\n  max_pyramid_level: 3\n  downscale: 2\n</code></pre> Key Type Description chunk_size list[int] (optional) Dimensions of the data chunks stored in the Zarr array Defaults to [1, 512, 512]. max_pyramid_level int (optional) Number of multiscale pyramid levels to generate. Defaults to 4. downscale int (optional) Downsampling factor applied between consecutive pyramid levels. Defaults to 2."},{"location":"usage/execution_modes/","title":"Usage","text":"<p>PlexPipe supports command-line execution and interactive analysis via Jupyter notebooks. For scalable workflows, it can also be orchestrated through Nextflow (see plex-pipe-nextflow).</p>"},{"location":"usage/execution_modes/#interactive-steps-1-core-detection-and-x-quality-control-are-designed-to-be-executed-using-napari","title":"Interactive steps (1 - Core detection and x - Quality Control) are designed to be executed using Napari)","text":""},{"location":"usage/execution_modes/#command-line-usage","title":"Command-Line Usage","text":"<p>To run the pipeline from the command line, use the provided scripts:</p>"},{"location":"usage/execution_modes/#prepare-cores","title":"Prepare Cores","text":"<pre><code>python scripts/prepare_cores.py --config config/analysis_pipeline.yaml\n</code></pre> <p>This script wraps the <code>CoreController</code> class, which handles:</p> <ul> <li>Reading image and metadata files.</li> <li>Cutting out cores with appropriate margins and masking.</li> <li>Writing intermediate TIFFs.</li> <li>Assembling per-core Zarr datasets using the SpatialData model.</li> </ul> <p>For more details, see the <code>core_cutter.py</code> source and its configuration.</p>"},{"location":"usage/execution_modes/#jupyter-notebook-usage","title":"Jupyter Notebook Usage","text":"<p>For interactive inspection, prototyping, or educational purposes, the following notebooks illustrate how to use the components directly:</p> <ul> <li><code>core_selection_demo.ipynb</code>: An interactive notebook that enables users to define cores as rectangles or polygons using the Napari viewer. It supports automatic core detection via Segment Anything v2, with the option to manually correct the detected shapes or draw new ones from scratch. This step is interactive and only available as a notebook. The result is a <code>core_info.csv</code> file containing core metadata for use in subsequent steps via either Jupyter or CLI.</li> <li><code>core_cutting_demo.ipynb</code>: Demonstrates how to load a single image and metadata entry and apply the core cutting logic.</li> </ul>"},{"location":"usage/input_data/","title":"Input Data","text":""},{"location":"usage/input_data/#file-naming-convention","title":"File Naming Convention","text":"<p>The pipeline expects OME-TIFF files to follow a specific naming convention (typical of processed CellDive data). The filename is parsed to extract the round number and marker name.</p> <p>Format: <code>[Prefix]_[Round].0.4_R000_[Dye]_[Marker]-[Suffix].ome.tif</code></p> <ul> <li>Round: Extracted from the second segment (e.g., <code>001</code> from <code>..._1.0.4_...</code>).</li> <li>Marker:<ul> <li>If the <code>[Dye]</code> segment contains \"DAPI\", the marker is set to <code>DAPI</code>.</li> <li>Otherwise, the marker is extracted from the <code>[Marker]</code> segment (everything before the first hyphen <code>-</code>).</li> </ul> </li> </ul> <p>Example:</p> <ul> <li>File: <code>BLCA-1_1.0.4_R000_Cy3_pH2AX-AF555_FINAL_AFR_F.ome.tif</code></li> <li>Round: 1</li> <li>Marker: pH2AX</li> <li>Channel Name: <code>001_pH2AX</code></li> </ul>"},{"location":"usage/input_data/#sourcing-image-files","title":"Sourcing Image Files","text":"<p>Original tiff files are required to divide into separate SpatialData objects in the Core Cutting step.</p> <p>Core cutting supports two modes of operation:</p> <ul> <li>Local mode: Tiff files are available on the local filesystem.</li> <li>Globus mode: Tiff files are accessed remotely using Globus endpoints.</li> </ul> <p>Differences in local vs. Globus mode come from how OME-TIFF files are sourced.</p>"},{"location":"usage/input_data/#local-mode","title":"\ud83d\udcf0 Local Mode","text":"<p>In local mode, <code>image_dir</code> should point to a folder with accessible OME-TIFF files on disk.</p> <pre><code>image_dir: \"C:/path_to_image_directory\"\n</code></pre>"},{"location":"usage/input_data/#globus-mode","title":"\u2601\ufe0f Globus Mode","text":"<p>In Globus mode, you must also specify the path to a Globus configuration directory. The <code>image_dir</code> field should reflect the remote directory on the Globus endpoint:</p> <pre><code>image_dir: \"/my_globus/path_to_image_directory\"\n</code></pre> <p>This allows the pipeline to discover and transfer files on demand via Globus.</p> <p>Work in progress explain Globus settings file.</p>"},{"location":"usage/installation/","title":"Installation Guide: PlexPipe GPU","text":"<p>This guide covers the setup for PlexPipe with GPU support. Following these steps in order is critical to ensure that the segmentation engines (InstanSeg, Cellpose) can access your hardware acceleration.</p>"},{"location":"usage/installation/#prerequisites","title":"\ud83d\udccb Prerequisites","text":"<ul> <li>NVIDIA GPU:</li> <li>NVIDIA Driver: Version 570.xx or higher (Required for CUDA 12.8).</li> <li>Conda: Miniconda or Anaconda installed.</li> </ul>"},{"location":"usage/installation/#conda-step-by-step-setup","title":"Conda Step-by-Step Setup","text":""},{"location":"usage/installation/#1-create-a-clean-environment","title":"1. Create a Clean Environment","text":"<p>Open your terminal (PowerShell or Anaconda Prompt) and create a fresh environment.</p> <pre><code>conda create -n plex-pipe-gpu python=3.12 git setuptools=80.10.2 -c conda-forge -y\nconda activate plex-pipe-gpu\n</code></pre>"},{"location":"usage/installation/#2-identify-and-install-pytorch-cuda-check","title":"2. Identify and Install PyTorch (CUDA Check)","text":"<p>Before installing, you must check which CUDA version your driver supports. Run the following command:</p> <p><pre><code>nvidia-smi\n</code></pre> Look at the top-right corner of the table for \"CUDA Version: XX.X\".</p> <p>Install pytorch-cuda version that matches your CUDA version. For example for CUDA 12.8:</p> <pre><code>pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu128\n</code></pre>"},{"location":"usage/installation/#3-install-segmentation-libraries","title":"3. Install Segmentation Libraries","text":"<pre><code>pip install cellpose instanseg-torch\n</code></pre>"},{"location":"usage/installation/#3-install-napari","title":"3. Install Napari","text":"<p>We install napari with the [all] extra to ensure the GUI and Qt backend are included, followed by instanseg.</p> <pre><code>pip install \"napari[all]\"\n</code></pre>"},{"location":"usage/installation/#4-clone-and-install-plexpipe","title":"4. Clone and Install PlexPipe","text":"<p>Instead of installing directly, clone the repository to your computer so you can access the provided examples and notebooks.</p>"},{"location":"usage/installation/#navigate-to-where-you-want-to-keep-the-code-eg-analysis-pipelines","title":"Navigate to where you want to keep the code (e.g., analysis-pipelines)","text":"<pre><code>cd analysis-pipelines\n</code></pre>"},{"location":"usage/installation/#clone-the-repository","title":"Clone the repository","text":"<pre><code>git clone https://github.com/StallaertLab/plex-pipe.git\ncd plex-pipe\n</code></pre>"},{"location":"usage/installation/#install-in-editable-mode-this-links-the-folder-to-your-environment","title":"Install in editable mode (this links the folder to your environment)","text":"<pre><code>pip install -e .\n</code></pre>"},{"location":"usage/processors/","title":"Available Processors","text":"<p>Processors are modular operations used within Step 04: Image Processing.</p>"},{"location":"usage/processors/#image-enhancers","title":"Image Enhancers","text":""},{"location":"usage/processors/#denoise_with_median","title":"<code>denoise_with_median</code>","text":"<p>Applies a median filter to the image.</p> Technical Specs <ul> <li>Inputs: 1</li> <li>Outputs: 1</li> <li>Parameters:<ul> <li><code>disk_radius</code> (default=<code>3</code>): The radius of the disk-shaped kernel for the median filter."},{"location":"usage/processors/#mean_of_images","title":"<code>mean_of_images</code>","text":"<p>Compute the mean of multiple image arrays.</p> Technical Specs <ul> <li>Inputs: Variable</li> <li>Outputs: 1</li> <li>Parameters: None.</li> </ul>"},{"location":"usage/processors/#normalize","title":"<code>normalize</code>","text":"<p>Performs percentile-based normalization on the image.</p> Technical Specs <ul> <li>Inputs: 1</li> <li>Outputs: 1</li> <li>Parameters:<ul> <li><code>low</code> (default=<code>1.0</code>): Lower percentile bound (0-100). <li><code>high</code> (default=<code>99.0</code>): Upper percentile bound (0-100)."},{"location":"usage/processors/#mask-builders","title":"Mask Builders","text":""},{"location":"usage/processors/#blob","title":"<code>blob</code>","text":"<p>Generates a coarse, smoothed binary mask (a 'blob') to define valid tissue regions. The input can be a marker image or a segmentation mask, and the output is a binary mask where 1 indicates tissue presence and 0 indicates background.</p> <p>It creates a simplified representation of the input by:</p> <ul> <li> <p>Binarization: Converting the input to a binary format (signal higher than 0 becomes 1).</p> </li> <li> <p>Rescaling: Downsampling the input to a lower resolution (<code>work_shape</code>) to blur individual small detections into aggregate clusters.</p> </li> <li> <p>Morphological Opening: Removing small, isolated noise clusters that do not form a significant mass.</p> </li> <li> <p>Morphological Closing: Fusing nearby clusters into solid 'blobs' and filling internal holes.</p> </li> <li> <p>Rescaling: Upsampling back to the original resolution to be used as a bitmask.</p> </li> </ul> <p>Common Use Cases:</p> <ul> <li>Tissue Masking: Run this on an initial segmentation mask to identify the broad footprint of the tissue. The resulting blob mask can then be multiplied with the original segmentation to automatically \"clip\" or \"clean\" any false-positive detections occurring in the very sparse regions beyond the actual tissue boundary.</li> </ul> Technical Specs <ul> <li>Inputs: 1</li> <li>Outputs: 1</li> <li>Parameters:<ul> <li><code>work_shape</code> (Tuple[int, int]default=<code>(250, 250)</code>): The resolution at which the blob is calculated. Lowering this value makes the processor more 'forgiving' of gaps but coarser in detail.</li> <li><code>radius</code> (default=<code>5</code>): The size of the disk used to open and close the mask. Larger values result in smoother, more rounded blobs."},{"location":"usage/processors/#multiply","title":"<code>multiply</code>","text":"<p>Multiplies two masks (intersection).</p> Technical Specs <ul> <li>Inputs: 2</li> <li>Outputs: 1</li> <li>Parameters: None.</li> </ul>"},{"location":"usage/processors/#ring","title":"<code>ring</code>","text":"<p>Creates annular (ring-shaped) regions of interest from an existing labeled mask. It is topology-aware: it ensures that even when objects are packed closely together, the rings respect the boundaries of neighboring labels rather than overlapping or merging. It handles both expansion and contraction.</p> <p>Common Use Cases:</p> <ul> <li> <p>The \"Nuclear Envelope\" Ring: To capture the region immediately surrounding a nucleus, set rad_bigger=3 and rad_smaller=0. This starts the ring at the nuclear boundary and extends it 5 pixels into the cytoplasm.</p> </li> <li> <p>The \"Internal Cortical\" Ring: To capture the area just inside the cell membrane, set rad_bigger=0 and rad_smaller=-3. This keeps the original boundary and \"hollows out\" the center.</p> </li> <li> <p>The \"Cytoplasmic Gap Ring\": To capture an area that doesn't touch the original label (a \"halo\"), set rad_bigger=7 and rad_smaller=2.</p> </li> </ul> Technical Specs <ul> <li>Inputs: 1</li> <li>Outputs: 1</li> <li>Parameters:<ul> <li><code>rad_bigger</code> (default=<code>7</code>): Outer boundary radius (px). Positive expands, negative erodes. <li><code>rad_smaller</code> (default=<code>2</code>): Inner boundary radius (px). Positive expands, negative erodes."},{"location":"usage/processors/#subtract","title":"<code>subtract</code>","text":"<p>Subtracts one mask from another (mask1 - mask2).</p> <p>Common Use Cases:</p> <ul> <li>Cytoplasm: To capture the cytoplasmic region of a cell, you can subtract the nuclear mask from the whole cell mask.</li> </ul> Technical Specs <ul> <li>Inputs: 2</li> <li>Outputs: 1</li> <li>Parameters: None.</li> </ul>"},{"location":"usage/processors/#object-segmenters","title":"Object Segmenters","text":""},{"location":"usage/processors/#cellpose","title":"<code>cellpose</code>","text":"<p>Uses the Cellpose deep learning model for segmentation.</p> Technical Specs <ul> <li>Inputs: Variable</li> <li>Outputs: 1</li> <li>Parameters:<ul> <li><code>diameter</code> (Optional[float]default=<code>30</code>): From Cellpose documentation: Scaling factor for the segmentation. Default size of cells 30 - segments well objects of size 10 -120.</li> <li><code>flow_threshold</code> (Optional[float]default=<code>0.4</code>): From Cellpose documentation: Maximum allowed flow error per mask (flow_threshold, default = 0.4). Increase it if too few ROIs are detected; decrease it if too many poor-quality ROIs appear.</li> <li><code>cellprob_threshold</code> (Optional[float]default=<code>0</code>): From Cellpose documentation: Pixel threshold to define ROIs. Lower the threshold if too few ROIs are detected; raise it if too many\u2014especially from dim regions.</li> <li><code>niter</code> (Optional[int]default=<code>0</code>): From Cellpose documentation: If niter is None or 0, it scales with ROI size\u2014use larger values (e.g., niter=2000) for longer ROIs.</li> </ul> </li> </ul>"},{"location":"usage/processors/#instanseg","title":"<code>instanseg</code>","text":"<p>Uses the InstanSeg deep learning model for segmentation.</p> Technical Specs <ul> <li>Inputs: Variable</li> <li>Outputs: Variable</li> <li>Parameters:<ul> <li><code>model</code> (Literal['fluorescence_nuclei_and_cells', 'brightfield_nuclei']default=<code>fluorescence_nuclei_and_cells</code>): Choice of pre-trained InstanSeg model.</li> <li><code>pixel_size</code> (default=<code>0.3</code>): Scaling factor for the segmentation. <li><code>resolve_cell_and_nucleus</code> (default=<code>True</code>): Internal InstanSeg parameter. If True, both cell and nucleus masks will be returned. If False, only the cell mask will be returned. <li><code>cleanup_fragments</code> (default=<code>True</code>): Internal InstanSeg parameter. <li><code>clean_cache</code> (default=<code>False</code>): If True, the CUDA cache is cleared after segmentation. <li><code>normalise</code> (default=<code>True</code>): Internal InstanSeg parameter. Controls whether the image is normalised. <li><code>overlap</code> (default=<code>80</code>): Internal InstanSeg parameter. The overlap (in pixels) between tiles."}]}