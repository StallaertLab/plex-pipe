{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ecb4129",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KMK280\\AppData\\Local\\miniconda3\\envs\\instanseg-env\\Lib\\site-packages\\dask\\dataframe\\__init__.py:31: FutureWarning: The legacy Dask DataFrame implementation is deprecated and will be removed in a future version. Set the configuration option `dataframe.query-planning` to `True` or None to enable the new Dask Dataframe implementation and silence this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\KMK280\\AppData\\Local\\miniconda3\\envs\\instanseg-env\\Lib\\site-packages\\xarray_schema\\__init__.py:1: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import DistributionNotFound, get_distribution\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from instanseg import InstanSeg\n",
    "import spatialdata as sd\n",
    "import napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dd63f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fluorescence_nuclei_and_cells version 0.1.1 already downloaded in D:\\instanseg\\instanseg\\utils\\../bioimageio_models/, loading\n",
      "Requesting default device: cuda\n"
     ]
    }
   ],
   "source": [
    "model = InstanSeg(\"fluorescence_nuclei_and_cells\", verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e96d406",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "version mismatch: detected: RasterFormatV02, requested: FormatV04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KMK280\\AppData\\Local\\miniconda3\\envs\\instanseg-env\\Lib\\site-packages\\zarr\\creation.py:610: UserWarning: ignoring keyword argument 'read_only'\n",
      "  compressor, fill_value = _kwargs_compat(compressor, fill_value, kwargs)\n",
      "version mismatch: detected: RasterFormatV02, requested: FormatV04\n",
      "version mismatch: detected: RasterFormatV02, requested: FormatV04\n",
      "version mismatch: detected: RasterFormatV02, requested: FormatV04\n",
      "version mismatch: detected: RasterFormatV02, requested: FormatV04\n",
      "version mismatch: detected: RasterFormatV02, requested: FormatV04\n",
      "version mismatch: detected: RasterFormatV02, requested: FormatV04\n",
      "version mismatch: detected: RasterFormatV02, requested: FormatV04\n",
      "version mismatch: detected: RasterFormatV02, requested: FormatV04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SpatialData object, with associated Zarr store: C:\\BLCA-2_Analysis_todel\\cores\\Core_000.zarr\n",
       "├── Images\n",
       "│     ├── 'CD11C': DataTree[cyx] (1, 5696, 5568), (1, 2848, 2784), (1, 1424, 1392)\n",
       "│     ├── 'CD44': DataTree[cyx] (1, 5696, 5568), (1, 2848, 2784), (1, 1424, 1392)\n",
       "│     ├── 'CD45': DataTree[cyx] (1, 5696, 5568), (1, 2848, 2784), (1, 1424, 1392)\n",
       "│     ├── 'DAPI': DataTree[cyx] (1, 5696, 5568), (1, 2848, 2784), (1, 1424, 1392)\n",
       "│     ├── 'HES1': DataTree[cyx] (1, 5696, 5568), (1, 2848, 2784), (1, 1424, 1392)\n",
       "│     ├── 'HLA1': DataTree[cyx] (1, 5696, 5568), (1, 2848, 2784), (1, 1424, 1392)\n",
       "│     ├── 'NaKATPase': DataTree[cyx] (1, 5696, 5568), (1, 2848, 2784), (1, 1424, 1392)\n",
       "│     ├── 'pCK26': DataTree[cyx] (1, 5696, 5568), (1, 2848, 2784), (1, 1424, 1392)\n",
       "│     └── 'pS6': DataTree[cyx] (1, 5696, 5568), (1, 2848, 2784), (1, 1424, 1392)\n",
       "└── Labels\n",
       "      ├── 'blob': DataTree[yx] (5696, 5568), (2848, 2784), (1424, 1392)\n",
       "      ├── 'cytoplasm': DataTree[yx] (5696, 5568), (2848, 2784), (1424, 1392)\n",
       "      ├── 'instanseg_cell': DataTree[yx] (5696, 5568), (2848, 2784), (1424, 1392)\n",
       "      ├── 'instanseg_nucleus': DataTree[yx] (5696, 5568), (2848, 2784), (1424, 1392)\n",
       "      └── 'ring': DataTree[yx] (5696, 5568), (2848, 2784), (1424, 1392)\n",
       "with coordinate systems:\n",
       "    ▸ 'global', with elements:\n",
       "        CD11C (Images), CD44 (Images), CD45 (Images), DAPI (Images), HES1 (Images), HLA1 (Images), NaKATPase (Images), pCK26 (Images), pS6 (Images), blob (Labels), cytoplasm (Labels), instanseg_cell (Labels), instanseg_nucleus (Labels), ring (Labels)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd_path = r'C:\\BLCA-2_Analysis_todel\\cores\\Core_000.zarr' \n",
    "sdata = sd.read_zarr(sd_path)\n",
    "sdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43fbe166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 5696, 5568)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channels = ['DAPI','NaKATPase']\n",
    "input_image = [np.array(sdata[ch]['scale0'].image) for ch in channels]\n",
    "input_image = np.stack(input_image).squeeze()\n",
    "input_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "814ac0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\instanseg\\instanseg\\utils\\pytorch_utils.py:215: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\SparseCsrTensorImpl.cpp:55.)\n",
      "  intersection = torch.sparse.mm(onehot1, onehot2.T).to_dense()\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 423 is out of bounds for dimension 0 with size 423",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m labeled_output, _ = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43meval_medium_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresolve_cell_and_nucleus\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpixel_size\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m segm_arrays = [np.array(x).astype(\u001b[38;5;28mint\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m labeled_output[\u001b[32m0\u001b[39m, :, :, :]]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\instanseg\\instanseg\\inference_class.py:510\u001b[39m, in \u001b[36mInstanSeg.eval_medium_image\u001b[39m\u001b[34m(self, image, pixel_size, normalise, tile_size, batch_size, return_image_tensor, normalisation_subsampling_factor, target, rescale_output, **kwargs)\u001b[39m\n\u001b[32m    506\u001b[39m instanseg_kwargs = _filter_kwargs(\u001b[38;5;28mself\u001b[39m.instanseg, kwargs)\n\u001b[32m    507\u001b[39m instanseg_kwargs[\u001b[33m\"\u001b[39m\u001b[33mtarget_segmentation\u001b[39m\u001b[33m\"\u001b[39m] = target_segmentation\n\u001b[32m--> \u001b[39m\u001b[32m510\u001b[39m instances = \u001b[43m_sliding_window_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    511\u001b[39m \u001b[43m                                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minstanseg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    512\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtile_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtile_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43msw_device\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minference_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    513\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcpu\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    514\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    515\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43moutput_channels\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dimension\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    516\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    517\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minstanseg_kwargs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43minstanseg_kwargs\u001b[49m\u001b[43m)\u001b[49m.float()\n\u001b[32m    519\u001b[39m instances = _to_ndim(instances, \u001b[32m4\u001b[39m)\n\u001b[32m    520\u001b[39m image = _to_ndim(image, \u001b[32m4\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\instanseg\\instanseg\\utils\\tiling.py:354\u001b[39m, in \u001b[36m_sliding_window_inference\u001b[39m\u001b[34m(input_tensor, predictor, window_size, overlap, max_cell_size, sw_device, device, output_channels, show_progress, batch_size, instanseg_kwargs)\u001b[39m\n\u001b[32m    347\u001b[39m lab, remapping_list = _stitch([lab[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m lab \u001b[38;5;129;01min\u001b[39;00m label_list],\n\u001b[32m    348\u001b[39m                         shape=window_size,\n\u001b[32m    349\u001b[39m                         chop_list=tuple_index,\n\u001b[32m    350\u001b[39m                         offset = overlap,\n\u001b[32m    351\u001b[39m                         final_shape=(\u001b[32m1\u001b[39m, input_tensor.shape[\u001b[32m1\u001b[39m], input_tensor.shape[\u001b[32m2\u001b[39m])) \n\u001b[32m    353\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_channels > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m     labs = torch.cat(\u001b[43m[\u001b[49m\u001b[43m_stitch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlab\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlab\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlabel_list\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mchop_list\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtuple_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m                        \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43moverlap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mfinal_shape\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mremapping_list\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mremapping_list\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43moutput_channels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m, dim=\u001b[32m0\u001b[39m) \n\u001b[32m    361\u001b[39m     lab = torch.cat([lab, labs], dim=\u001b[32m0\u001b[39m)\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m lab[\u001b[38;5;28;01mNone\u001b[39;00m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\instanseg\\instanseg\\utils\\tiling.py:354\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    347\u001b[39m lab, remapping_list = _stitch([lab[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m lab \u001b[38;5;129;01min\u001b[39;00m label_list],\n\u001b[32m    348\u001b[39m                         shape=window_size,\n\u001b[32m    349\u001b[39m                         chop_list=tuple_index,\n\u001b[32m    350\u001b[39m                         offset = overlap,\n\u001b[32m    351\u001b[39m                         final_shape=(\u001b[32m1\u001b[39m, input_tensor.shape[\u001b[32m1\u001b[39m], input_tensor.shape[\u001b[32m2\u001b[39m])) \n\u001b[32m    353\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_channels > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m     labs = torch.cat([\u001b[43m_stitch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlab\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlab\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlabel_list\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mchop_list\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtuple_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m                        \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43moverlap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mfinal_shape\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mremapping_list\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mremapping_list\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m,output_channels)], dim=\u001b[32m0\u001b[39m) \n\u001b[32m    361\u001b[39m     lab = torch.cat([lab, labs], dim=\u001b[32m0\u001b[39m)\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m lab[\u001b[38;5;28;01mNone\u001b[39;00m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\instanseg\\instanseg\\utils\\tiling.py:146\u001b[39m, in \u001b[36m_stitch\u001b[39m\u001b[34m(tiles, shape, chop_list, final_shape, offset, remapping_list)\u001b[39m\n\u001b[32m    142\u001b[39m     tile2 = _remove_edge_labels(new_tile[:,offset :shape[\u001b[32m0\u001b[39m],: shape[\u001b[32m1\u001b[39m]], ignore = ignore_list)\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m edge_window:\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m     tile2, index_map = \u001b[43mtorch_fastremap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtile2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_map\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_map\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    147\u001b[39m     tile2[tile2>\u001b[32m0\u001b[39m] = tile2[tile2>\u001b[32m0\u001b[39m] + running_max\n\u001b[32m    149\u001b[39m     remapped = match_labels(tile1, tile2, threshold = \u001b[32m0.1\u001b[39m)[\u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\instanseg\\instanseg\\utils\\pytorch_utils.py:39\u001b[39m, in \u001b[36mtorch_fastremap\u001b[39m\u001b[34m(x, index_map, return_map)\u001b[39m\n\u001b[32m     37\u001b[39m     valid = torch.isin(x, index_map[\u001b[32m0\u001b[39m], assume_unique=\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m#only for nuclei that were not removed from the edge while cells were\u001b[39;00m\n\u001b[32m     38\u001b[39m     x[~valid] = \u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     y = \u001b[43mremap_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (y, index_map) \u001b[38;5;28;01mif\u001b[39;00m return_map \u001b[38;5;28;01melse\u001b[39;00m y\n\u001b[32m     43\u001b[39m unique_values = torch.unique(x, \u001b[38;5;28msorted\u001b[39m=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\instanseg\\instanseg\\utils\\pytorch_utils.py:15\u001b[39m, in \u001b[36mremap_values\u001b[39m\u001b[34m(remapping, x)\u001b[39m\n\u001b[32m     13\u001b[39m sorted_remapping = remapping[:, remapping[\u001b[32m0\u001b[39m].argsort()]\n\u001b[32m     14\u001b[39m index = torch.bucketize(x.ravel(), sorted_remapping[\u001b[32m0\u001b[39m])\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msorted_remapping\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m.reshape(x.shape)\n",
      "\u001b[31mIndexError\u001b[39m: index 423 is out of bounds for dimension 0 with size 423"
     ]
    }
   ],
   "source": [
    "labeled_output, _ = model.eval_medium_image(input_image, resolve_cell_and_nucleus = True, pixel_size =0.3)\n",
    "segm_arrays = [np.array(x).astype(int) for x in labeled_output[0, :, :, :]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14121047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 5696, 5568])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac276f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'Labels [1]' at 0x1c59e485b50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_labels(segm_arrays[1])\n",
    "viewer.add_labels(segm_arrays[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2d6645ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], shape=(5696, 5568))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segm_arrays[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0d246810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12932, 12933, 12934, ..., 26416, 26418, 26419], shape=(1392,))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.setdiff1d(segm_arrays[1], segm_arrays[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf86b6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdata-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
